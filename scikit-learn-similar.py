from pathlib import Path
from typing import Tuple
from sklearn.feature_extraction.text import TfidfVectorizer
import numpy as np
from cosine_similarity import cosine_similarity  # Your existing cosine similarity function

"""
Test script generated by chatgpt for comparison with my own script.
"""


def most_similar(input_document: str, corpus: list[str]) -> Tuple[str, float]:
    # Initialize vectorizer with simple tokenization (can customize)
    vectorizer = TfidfVectorizer(lowercase=True, token_pattern=r'\b\w+\b')

    # Fit on corpus and transform corpus to tf-idf vectors
    corpus_vectors = vectorizer.fit_transform(corpus)

    # Transform the input document to tf-idf vector (using same vectorizer)
    input_vector = vectorizer.transform([input_document])

    highest = -1
    most_similar_doc = ""

    # Iterate over corpus vectors to find highest cosine similarity
    for i, doc_vector in enumerate(corpus_vectors):
        # Convert sparse vectors to dense for your cosine_similarity function if needed
        sim = cosine_similarity(
            input_vector.toarray()[0].tolist(),
            doc_vector.toarray()[0].tolist()
        )
        print(f"Similarity with doc {i}: {sim}")
        if sim > highest:
            highest = sim
            most_similar_doc = corpus[i]

    return most_similar_doc, highest


def main():
    path = Path("./test-docs/")
    corpus_list = []

    for p in path.iterdir():
        with open(p, encoding="utf-8") as f:
            corpus_list.append(f.read())

    with open("./input.txt", "r", encoding="utf-8") as input_file:
        input_doc = input_file.read()

    most_sim_doc, similarity = most_similar(input_doc, corpus_list)
    print(f"\nMost similar doc (score {similarity:.4f}):\n{most_sim_doc}")


if __name__ == "__main__":
    main()
