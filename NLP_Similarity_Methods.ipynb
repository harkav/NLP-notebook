{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d454e27e-b7ca-4801-9a7c-76a6f300cfa7",
   "metadata": {},
   "source": [
    "# NLP similarity and methods - first exploration of the vector space. \n",
    "\n",
    "## Content: \n",
    "- Readme\n",
    "- Setup, tests\n",
    "- Comprehensions\n",
    "- On the numerical representation of natural language\n",
    "- Bag of word\n",
    "- [Dot product](#dot-product)\n",
    "- Euclidean distance\n",
    "- Length Normalization\n",
    "- Cosine similarity\n",
    "- TF-IDF\n",
    "- Mini project: Finding the most similar document using cosine similarity and TF-IDF\n",
    "- Mini project revisited: doing the same, just with professional libraries.\n",
    "- About, credits, where to learn more, and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbd1d7cd-e527-4a08-b146-db938c0ea72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  .MathJax_Display, .MathJax {\n",
       "    font-size: 250% !important;\n",
       "  }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to make the math formulas larger.\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML('''\n",
    "<style>\n",
    "  .MathJax_Display, .MathJax {\n",
    "    font-size: 250% !important;\n",
    "  }\n",
    "</style>\n",
    "'''))\n",
    "\n",
    "# thanks to chatgpt for the css \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f2d8e3-9ca2-4873-9216-e8ecea9ef2a4",
   "metadata": {},
   "source": [
    "# Readme\n",
    "\n",
    "This is the first notebook of what I hope to be a series of notebooks, covering the curriculum of a course at UiO, in2110. \n",
    "\n",
    "In this notebook, we'll go through some of the basic concepts of algoirthms, and after that, we'll end with a small final project, demonstrating the algoritms.\n",
    "\n",
    "The final project comes in two different versions, one using my own implementations and one using more professional libraries. The reason is that this will both teach me how to implement the algoirthms myself, but also how to use the standard libraries for these kind of tasks properly. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f19bf15-1e8d-4ee7-872f-6a4504f9c9f3",
   "metadata": {},
   "source": [
    "# Setup and tests\n",
    "\n",
    "## Requirements.txt\n",
    "See requirements.txt\n",
    "\n",
    "## How to run\n",
    "## Folder structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ae637f-76e8-4514-8b77-c841a5184dcb",
   "metadata": {},
   "source": [
    "# Comprehensions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32effb12-313f-495f-ab19-81a287f2754a",
   "metadata": {},
   "source": [
    "# On the numerical representation of natural language, and what is a vector anyways? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9413ea6-7520-4774-8f5f-e81fc2fcf5e6",
   "metadata": {},
   "source": [
    "# Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1925ff6d-3a05-463f-a716-8da480ad169e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "stopwords = set(stopwords.words(\"norwegian\"))\n",
    "#print(stopwords)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    with open(\"epiktet-frihet.txt\", \"r\", encoding=\"utf-8\") as f: \n",
    "        sample = f.read()\n",
    "        sample = preprocess(sample)\n",
    "\n",
    "\n",
    "\n",
    "    counter_dict = Counter(word_tokenize(sample))\n",
    "    sorted_counter_dict = counter_dict.most_common(25)\n",
    "\n",
    "    for k in sorted_counter_dict: \n",
    "        print(k)\n",
    "\n",
    "    \n",
    "    visualize(counter_dict)\n",
    "    \n",
    "def preprocess(text : str) -> str: \n",
    "    \"\"\"\n",
    "    Removes html-tags from text.\n",
    "    \n",
    "    Args: \n",
    "        text (str): the input text.\n",
    "        \n",
    "    Returns: \n",
    "        cleaned_text (str): the cleaned text.\n",
    "    \"\"\"\n",
    "    text = re.sub(\"<.*?>\", \"\", text)\n",
    "    text = re.sub(\"[^\\w\\s]\", \" \", text, flags=re.UNICODE)\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "def visualize(counter_dict : Counter) -> None:\n",
    "    most_common = counter_dict.most_common(15)\n",
    "    words, freq = zip(*most_common)\n",
    "    \n",
    "    plt.bar(words, freq)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(\"Top 15 words\")\n",
    "    plt.savefig(\"plot.jpg\")\n",
    "    \n",
    "    wordcloud = WordCloud().generate_from_frequencies(counter_dict)\n",
    "    wordcloud.to_file(\"kvakk.jpg\")\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6451731b-ec3a-4955-95b2-7b7cee62f7b4",
   "metadata": {},
   "source": [
    "# Dot-product\n",
    "\n",
    "The forumla for finding the dot product is the following: \n",
    "\n",
    "$a \\cdot b =\\sum_{i=0}^{n - 1}(a_ib_i)$\n",
    "\n",
    "\n",
    "In other words, for each feature in vector a and b, take the sum of the product of feature i in vector a with feature i in vector b from index 0 to the last index of the vectors. (Where we count index 0 as the first index of a vector.) The algorithm assumes that the vectors are of equal length. \n",
    "\n",
    "Example: \n",
    "\n",
    "a = [1, 2, 3]\n",
    "\n",
    "b = [2, 2, 2]\n",
    "\n",
    "dot product = ((1 * 2) + (2 * 2) + (3 * 2) ) = 12\n",
    "\n",
    "Example 2: \n",
    "\n",
    "a = [1, 1, 7]\n",
    "\n",
    "b = [2, 3, 6]\n",
    "\n",
    "dot product = ((1 * 2) + (1 * 3) + (7 * 6) ) = 47\n",
    "\n",
    "\n",
    "Example 3: \n",
    "\n",
    "a = [0]\n",
    "\n",
    "b = [1]\n",
    "\n",
    "dot product = 0 * 1 = 0\n",
    "\n",
    "\n",
    "Here is an implementation in Python, meant to be readable. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b161a3a-1fd9-46ff-bab3-f08171581b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot product, [1, 2, 3], [2, 2, 2] = 12\n",
      "Dot product, [1, 1, 7], [2, 3, 6] = 47\n",
      "Dot product, [0], [1] = 0\n"
     ]
    }
   ],
   "source": [
    "def dot_product(vector1: list[float], vector2 : list[float]) -> float :\n",
    "    \"\"\"\n",
    "    A method for finding the dot product of two vectors.\n",
    "    \n",
    "    Args: \n",
    "        vector1 (list[float]): a list representing a vector.\n",
    "        vector2 (list[float]): a list representing a different vector. \n",
    "        \n",
    "    Returns: \n",
    "        sum (float): the sum of the calculation.\n",
    "        \n",
    "    Raises: \n",
    "        ValueError: If the vectors are not of the same length. \n",
    "    \"\"\"\n",
    "    \n",
    "    if len(vector1) != len(vector2):\n",
    "        raise ValueError(\"Vectors must be of the same length\")\n",
    "        \n",
    "    \n",
    "    total = 0 \n",
    "    for v1, v2 in zip(vector1, vector2): \n",
    "        total += (v1 * v2)\n",
    "    return total\n",
    "\n",
    "print(f\"Dot product, [1, 2, 3], [2, 2, 2] = {dot_product([1, 2, 3], [2, 2, 2])}\" )\n",
    "print(f\"Dot product, [1, 1, 7], [2, 3, 6] = {dot_product([1, 1, 7], [2, 3, 6])}\" )\n",
    "print(f\"Dot product, [0], [1] = {dot_product([0], [1])}\" )\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b81c83d-16e7-4186-a174-e6c85a7d9652",
   "metadata": {},
   "source": [
    "# Euclidean distance\n",
    "\n",
    "The Euclidean distance between two vectors **a** and **b** is calculated as:\n",
    "\n",
    "$$\n",
    "d(a, b) = \\sqrt{\\sum_{i=1}^{n}(a_i - b_i)^2}\n",
    "$$\n",
    "\n",
    "\n",
    "#TODO add examples and calcuations. \n",
    "\n",
    "We can do this in a very straightforward way in Python like this: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b205dd4-e9a8-4e90-b5c2-d984908d7911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(\n",
    "        vector1: list[float], vector2 : list[float]\n",
    "        ) -> float :\n",
    "\n",
    "        if len(vector1) != len(vector2):\n",
    "            raise ValueError(\"Vectors must be of the same length\")\n",
    "            \n",
    "        \n",
    "        total = 0 \n",
    "        for v1, v2 in zip(vector1, vector2): \n",
    "            total += (v1 - v2)**2\n",
    "        return math.sqrt(total)\n",
    "\n",
    "# Or with a list comprehension\n",
    " def euclidean_distance(vector1, vector2): \n",
    "        return math.sqrt(sum( x - y) ** 2 for x, y in zip(vector1, vector2))\n",
    "\n",
    "#TODO add some example usage\n",
    "#TODO add docstring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b526a8be-bd0e-4efd-8822-15f143cd48ac",
   "metadata": {},
   "source": [
    "# Length normalization\n",
    "\n",
    "$$\\frac{x}{||x||}$$\n",
    "\n",
    "**Length of a vector**\n",
    "$$||x|| = \\sqrt{x \\cdot x} = \\sqrt{\\sum_{i=1}^nx_i^2}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2644666-ae29-42af-91a9-44de31e7d177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def length_normalization(vector: list[float]) -> list[float] :\n",
    "    \"\"\"\n",
    "    A method for normalizing a vector.\n",
    "    \n",
    "    Args: \n",
    "        vector1 (list[float]): a list representing a vector.\n",
    "         \n",
    "        \n",
    "    Returns: \n",
    "        normalized_vector (list[float]): the sum of the calculation.\n",
    "        \n",
    "    Raises: \n",
    "        ValueError: If it is a zero-length vector. \n",
    "    \"\"\"\n",
    "    \n",
    " \n",
    "    \n",
    "    total = 0\n",
    "    for element in vector: \n",
    "        total += element ** 2\n",
    "    length = math.sqrt(total)\n",
    "    \n",
    "    if length == 0: \n",
    "        raise ValueError(\"cannot normalize a zero-length vector\")\n",
    "    normalized_vector = [x/ length for x in vector]\n",
    "\n",
    "    return normalized_vector\n",
    "\n",
    "#TODO add doc strings and examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796ba0b0-760e-4b27-bc27-2c45553b8906",
   "metadata": {},
   "source": [
    "# Cosine similarity\n",
    "\n",
    "TODO - everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "356fca95-a65c-4b0a-8a68-65cc5699f8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vector1: list[float], vector2 : list[float]) -> float :\n",
    "    \"\"\"\n",
    "    A method for finding the cosine similarity of two vectors.\n",
    "    \n",
    "    Args: \n",
    "        vector1 (list[float]): a list representing a vector.\n",
    "        vector2 (list[float]): a list representing a different vector. \n",
    "        \n",
    "    Returns: \n",
    "        dotproduct (float): the dot product of the normalized vectors.\n",
    "        \n",
    "    Raises: \n",
    "        ValueError: If the vectors are not of the same length. \n",
    "    \"\"\"\n",
    "    \n",
    "    if len(vector1) != len(vector2):\n",
    "        raise ValueError(\"Vectors must be of the same length\")\n",
    "    if all(v == 0 for v in vector1) or all(v == 0 for v in vector2): \n",
    "        return 0.0\n",
    "        \n",
    "    \n",
    "    vector1_normalized = length_normalization(vector1)\n",
    "    vector2_normalized = length_normalization(vector2)\n",
    "    \n",
    "    return dot_product(vector1_normalized, vector2_normalized)\n",
    "\n",
    "#TODO add examples\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de65f082-2122-4714-a201-dc6aa028d1b0",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398ab710-4948-4e43-8531-a20877865d86",
   "metadata": {},
   "source": [
    "# Mini project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cac4d8-c1b0-46ee-badc-7d9e22661bc8",
   "metadata": {},
   "source": [
    "# Mini project - using external libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a175fc47-a247-4029-90ff-3afcf33fc9f0",
   "metadata": {},
   "source": [
    "# About, credits and so on. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
