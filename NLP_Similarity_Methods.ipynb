{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d454e27e-b7ca-4801-9a7c-76a6f300cfa7",
   "metadata": {},
   "source": [
    "# NLP similarity and methods - first exploration of the vector space. \n",
    "\n",
    "## Content: \n",
    "- Readme\n",
    "- Setup, tests\n",
    "- Tokenization\n",
    "- Comprehensions\n",
    "- On the numerical representation of natural language\n",
    "- Bag of word\n",
    "- [Dot product](#dot-product)\n",
    "- Euclidean distance\n",
    "- Length Normalization\n",
    "- Cosine similarity\n",
    "- TF-IDF\n",
    "- Mini project: Finding the most similar document using cosine similarity and TF-IDF\n",
    "- Mini project revisited: doing the same, just with professional libraries.\n",
    "- About, credits, where to learn more, and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd1d7cd-e527-4a08-b146-db938c0ea72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  .MathJax_Display, .MathJax {\n",
       "    font-size: 250% !important;\n",
       "  }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to make the math formulas larger.\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML('''\n",
    "<style>\n",
    "  .MathJax_Display, .MathJax {\n",
    "    font-size: 250% !important;\n",
    "  }\n",
    "</style>\n",
    "'''))\n",
    "\n",
    "# thanks to chatgpt for the css \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f2d8e3-9ca2-4873-9216-e8ecea9ef2a4",
   "metadata": {},
   "source": [
    "# Readme\n",
    "\n",
    "This is the first notebook of what I hope to be a series of notebooks, covering the curriculum of a course at UiO, in2110. \n",
    "\n",
    "In this notebook, we'll go through some of the basic concepts of algoirthms, and after that, we'll end with a small final project, demonstrating the algoritms.\n",
    "\n",
    "The final project comes in two different versions, one using my own implementations and one using more professional libraries. The reason is that this will both teach me how to implement the algoirthms myself, but also how to use the standard libraries for these kind of tasks properly. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f19bf15-1e8d-4ee7-872f-6a4504f9c9f3",
   "metadata": {},
   "source": [
    "# Setup and tests\n",
    "\n",
    "## Requirements.txt\n",
    "See requirements.txt\n",
    "\n",
    "## Folder structure\n",
    "TODO \n",
    "\n",
    "## How to run\n",
    "\n",
    "- Create venv (recommended)\n",
    "\n",
    "```bash\n",
    "python -m venv NLP-venv\n",
    "source ./NLP-venv/bin/actiavte\n",
    "pip install -r requirements.txt\n",
    "\n",
    "```\n",
    "Install jupyer notebook: \n",
    "Follow instructions here: <link>\n",
    "\n",
    "run jupyer notebook NLP-notebook.ipynb from root \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe6ed7d",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "\n",
    "## What is a token? \n",
    "- How many tokens is \"New York\" or \"Celine Dion\"? \n",
    "- Are puncts tokens or part of tokens? \n",
    "- Stop words \n",
    "\n",
    "\n",
    "## Tokens, types, lemmas \n",
    "\n",
    "## Ways of tokenizing\n",
    "\n",
    "- split()\n",
    "- using re\n",
    "- using nltk\n",
    "- writing your own: a bit hard. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ae637f-76e8-4514-8b77-c841a5184dcb",
   "metadata": {},
   "source": [
    "# Comprehensions\n",
    "\n",
    "Comprehensions are a way to create lists, sets, dictionaries and generators in a more pythonic and concise way. \n",
    "\n",
    "The basic syntax is [expression for variable in iterable if condition]\n",
    "\n",
    "\n",
    "While comprehensions aren't really a part of NLP in itself, it is so commonly used, both in my code and in others, that I \n",
    "think that it should be included in this notebook.\n",
    "\n",
    "Example: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4564dac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bob', 'Lars', 'Celine']\n"
     ]
    }
   ],
   "source": [
    "names = [\"Bob\", \"Lars\", \"Celine\"]\n",
    "\n",
    "# lower only names beginning with B, include all names. \n",
    "names = [name.lower() if name[0] == \"B\" else name for name in names]\n",
    "print(names)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a396612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{12345678: 'Bob', 22222222: 'Lars', 33333333: 'Celine'}\n"
     ]
    }
   ],
   "source": [
    "# Flip a dictionary: \n",
    "\n",
    "phone_book = {\n",
    "\n",
    "    \"Bob\": 12345678,\n",
    "    \"Lars\" : 22222222, \n",
    "    \"Celine\" : 33333333\n",
    "    \n",
    "}\n",
    "\n",
    "number_to_name_dict = {number : name for name, number in phone_book.items()}\n",
    "\n",
    "print(number_to_name_dict)\n",
    "\n",
    "# notice that there is a possibility of losing data her, if two names are linked to the same number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c58074d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'apple', 'banana'}\n"
     ]
    }
   ],
   "source": [
    "# Create a set from a list: \n",
    "\n",
    "fruit_list = [\"apple\", \"apple\", \"banana\"]\n",
    "\n",
    "fruit_set = {fruit for fruit in fruit_list}\n",
    "print(fruit_set)\n",
    "\n",
    "# notice the different brackets and how they affect the type of the comprehension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ec922d7-2cc3-42f7-af81-3d55e244d700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flat matrix: [1, 2, 3, 2, 3, 4, 3, 4, 5]\n",
      "flat set: {1, 2, 3, 4, 5}\n"
     ]
    }
   ],
   "source": [
    "# You can also do nested comprehensions, for instance to flatten a matrix. \n",
    "\n",
    "matrix = [[1, 2, 3],\n",
    "          [2, 3, 4], \n",
    "          [3, 4, 5]]\n",
    "\n",
    "flat_matrix = [v for vector in matrix for v in vector]\n",
    "print(f\"flat matrix: {flat_matrix}\")\n",
    "\n",
    "# or again, to return a set from a matrix: \n",
    "\n",
    "flat_set = {v for vector in matrix for v in vector}\n",
    "print(f\"flat set: {flat_set}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0f2425-fd0b-48ea-ac2a-398cc7ab0b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List comprehension:\n",
      "Elapsed time: 0.66 seconds\n",
      "Memory usage: 89,095,160 bytes (~84.97 MB)\n",
      "Generator\n",
      "Elapsed time: 0.00 seconds\n",
      "Memory usage: 200 bytes (~0.00 MB)\n",
      "0\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "25\n",
      "36\n",
      "49\n",
      "64\n",
      "81\n",
      "100\n",
      "121\n",
      "144\n",
      "169\n",
      "196\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mStopIteration\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 59\u001b[39m\n\u001b[32m     56\u001b[39m new_generator = (i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m3\u001b[39m)) \n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m4\u001b[39m): \n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_generator\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m# will throw StopIteration when the generator is exhausted. \u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# chatgpt help me think clearer about generators and provided the syntax for getting something out of a generator. \u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# It also helped me to find a good way to find how much is loaded into the memory. \u001b[39;00m\n\u001b[32m     63\u001b[39m \n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# If this is a bit fuzzy, then hopefully it will be clearer for both you and I as we use generators in real problems further down the line. \u001b[39;00m\n",
      "\u001b[31mStopIteration\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import time \n",
    "import sys \n",
    "# Generators \n",
    "\n",
    "# Generators are iterables that yield objects one at the time when they are needed. I.e, they are a way of avoiding storing a large \n",
    "# iterable in memory, and rather just load just as much as you need when you need it. \n",
    "# You've probably already used generators like file.readline() and range already. \n",
    "\n",
    "# The syntax is quite similar to the other comprehensions, though the expression is enclosed in () rather than [] or {}\n",
    "\n",
    "# Example: \n",
    "\n",
    "def square_10million_list_comprehension(): \n",
    "    \"\"\" Method for squaring  up to 10⁷ using a list comprehension. \"\"\"\n",
    "    start_time = time.time() \n",
    "    squares = [i**2 for i in range(10**7)] \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    memory_usage = sys.getsizeof(squares)\n",
    "    print(\"List comprehension:\")\n",
    "    print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "    print(f\"Memory usage: {memory_usage:,} bytes (~{memory_usage / (1024**2):.2f} MB)\")\n",
    " \n",
    "\n",
    "# uncomment the next line to run the list comprehension\n",
    "#square_10million_list_comprehension() \n",
    "\n",
    "# here is a generator version: \n",
    "\n",
    "def square_10million_generator(): \n",
    "    \"\"\" Method for squaring up to 10⁷ using a generator comprehension. \"\"\" \n",
    "    start_time = time.time() \n",
    "    squares = (i**2 for i in range(10**7)) \n",
    "    end_time = time.time()\n",
    "    print(\"Generator\")\n",
    "    elapsed_time = end_time - start_time\n",
    "    memory_usage = sys.getsizeof(squares)\n",
    "    print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "    print(f\"Memory usage: {memory_usage:,} bytes (~{memory_usage / (1024**2):.2f} MB)\")\n",
    "    return squares\n",
    "\n",
    "squares = square_10million_generator() \n",
    " \n",
    "# The generator has now been created, though nothing has yet been computed. \n",
    "\n",
    "\n",
    "# using the generator, getting the n first squares: \n",
    "\n",
    "n = 15\n",
    "\n",
    "for _ in range(15): \n",
    "    print(next(squares))\n",
    "\n",
    "\n",
    "# A final point is that generators can be exhausted: \n",
    "\n",
    "new_generator = (i for i in range(3)) \n",
    "\n",
    "n = 3 \n",
    "# Uncomment the line bellow to ask the generator to yield more even after it's exhausted. \n",
    "# n = 4\n",
    "for i in range(n): \n",
    "    print(next(new_generator)) \n",
    "\n",
    "# chatgpt help me think clearer about generators and provided the syntax for getting something out of a generator. \n",
    "# It also helped me to find a good way to find how much is loaded into the memory. \n",
    "\n",
    "# If this is a bit fuzzy, then hopefully it will be clearer for both you and I as we use generators in real problems further down the line. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32effb12-313f-495f-ab19-81a287f2754a",
   "metadata": {},
   "source": [
    "# On the numerical representation of natural language, and what is a vector anyways? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9413ea6-7520-4774-8f5f-e81fc2fcf5e6",
   "metadata": {},
   "source": [
    "# Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1925ff6d-3a05-463f-a716-8da480ad169e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "stopwords = set(stopwords.words(\"norwegian\"))\n",
    "#print(stopwords)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    with open(\"epiktet-frihet.txt\", \"r\", encoding=\"utf-8\") as f: \n",
    "        sample = f.read()\n",
    "        sample = preprocess(sample)\n",
    "\n",
    "\n",
    "\n",
    "    counter_dict = Counter(word_tokenize(sample))\n",
    "    sorted_counter_dict = counter_dict.most_common(25)\n",
    "\n",
    "    for k in sorted_counter_dict: \n",
    "        print(k)\n",
    "\n",
    "    \n",
    "    visualize(counter_dict)\n",
    "    \n",
    "def preprocess(text : str) -> str: \n",
    "    \"\"\"\n",
    "    Removes html-tags from text.\n",
    "    \n",
    "    Args: \n",
    "        text (str): the input text.\n",
    "        \n",
    "    Returns: \n",
    "        cleaned_text (str): the cleaned text.\n",
    "    \"\"\"\n",
    "    text = re.sub(\"<.*?>\", \"\", text)\n",
    "    text = re.sub(\"[^\\w\\s]\", \" \", text, flags=re.UNICODE)\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "def visualize(counter_dict : Counter) -> None:\n",
    "    most_common = counter_dict.most_common(15)\n",
    "    words, freq = zip(*most_common)\n",
    "    \n",
    "    plt.bar(words, freq)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(\"Top 15 words\")\n",
    "    plt.savefig(\"plot.jpg\")\n",
    "    \n",
    "    wordcloud = WordCloud().generate_from_frequencies(counter_dict)\n",
    "    wordcloud.to_file(\"kvakk.jpg\")\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6451731b-ec3a-4955-95b2-7b7cee62f7b4",
   "metadata": {},
   "source": [
    "# Dot-product\n",
    "\n",
    "The forumla for finding the dot product is the following: \n",
    "\n",
    "$a \\cdot b =\\sum_{i=0}^{n - 1}(a_ib_i)$\n",
    "\n",
    "\n",
    "In other words, for each feature in vector a and b, take the sum of the product of feature i in vector a with feature i in vector b from index 0 to the last index of the vectors. (Where we count index 0 as the first index of a vector.) The algorithm assumes that the vectors are of equal length. \n",
    "\n",
    "Example: \n",
    "\n",
    "a = [1, 2, 3]\n",
    "\n",
    "b = [2, 2, 2]\n",
    "\n",
    "dot product = ((1 * 2) + (2 * 2) + (3 * 2) ) = 12\n",
    "\n",
    "Example 2: \n",
    "\n",
    "a = [1, 1, 7]\n",
    "\n",
    "b = [2, 3, 6]\n",
    "\n",
    "dot product = ((1 * 2) + (1 * 3) + (7 * 6) ) = 47\n",
    "\n",
    "\n",
    "Example 3: \n",
    "\n",
    "a = [0]\n",
    "\n",
    "b = [1]\n",
    "\n",
    "dot product = 0 * 1 = 0\n",
    "\n",
    "\n",
    "Here is an implementation in Python, meant to be readable. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b161a3a-1fd9-46ff-bab3-f08171581b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot product, [1, 2, 3], [2, 2, 2] = 12\n",
      "Dot product, [1, 1, 7], [2, 3, 6] = 47\n",
      "Dot product, [0], [1] = 0\n"
     ]
    }
   ],
   "source": [
    "def dot_product(vector1: list[float], vector2 : list[float]) -> float :\n",
    "    \"\"\"\n",
    "    A method for finding the dot product of two vectors.\n",
    "    \n",
    "    Args: \n",
    "        vector1 (list[float]): a list representing a vector.\n",
    "        vector2 (list[float]): a list representing a different vector. \n",
    "        \n",
    "    Returns: \n",
    "        sum (float): the sum of the calculation.\n",
    "        \n",
    "    Raises: \n",
    "        ValueError: If the vectors are not of the same length. \n",
    "    \"\"\"\n",
    "    \n",
    "    if len(vector1) != len(vector2):\n",
    "        raise ValueError(\"Vectors must be of the same length\")\n",
    "        \n",
    "    \n",
    "    total = 0 \n",
    "    for v1, v2 in zip(vector1, vector2): \n",
    "        total += (v1 * v2)\n",
    "    return total\n",
    "\n",
    "print(f\"Dot product, [1, 2, 3], [2, 2, 2] = {dot_product([1, 2, 3], [2, 2, 2])}\" )\n",
    "print(f\"Dot product, [1, 1, 7], [2, 3, 6] = {dot_product([1, 1, 7], [2, 3, 6])}\" )\n",
    "print(f\"Dot product, [0], [1] = {dot_product([0], [1])}\" )\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b81c83d-16e7-4186-a174-e6c85a7d9652",
   "metadata": {},
   "source": [
    "# Euclidean distance\n",
    "\n",
    "The Euclidean distance between two vectors **a** and **b** is calculated as:\n",
    "\n",
    "$$\n",
    "d(a, b) = \\sqrt{\\sum_{i=1}^{n}(a_i - b_i)^2}\n",
    "$$\n",
    "\n",
    "\n",
    "#TODO add examples and calcuations. \n",
    "\n",
    "We can do this in a very straightforward way in Python like this: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b205dd4-e9a8-4e90-b5c2-d984908d7911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(\n",
    "        vector1: list[float], vector2 : list[float]\n",
    "        ) -> float :\n",
    "\n",
    "        if len(vector1) != len(vector2):\n",
    "            raise ValueError(\"Vectors must be of the same length\")\n",
    "            \n",
    "        \n",
    "        total = 0 \n",
    "        for v1, v2 in zip(vector1, vector2): \n",
    "            total += (v1 - v2)**2\n",
    "        return math.sqrt(total)\n",
    "\n",
    "# Or with a list comprehension\n",
    " def euclidean_distance(vector1, vector2): \n",
    "        return math.sqrt(sum( x - y) ** 2 for x, y in zip(vector1, vector2))\n",
    "\n",
    "#TODO add some example usage\n",
    "#TODO add docstring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b526a8be-bd0e-4efd-8822-15f143cd48ac",
   "metadata": {},
   "source": [
    "# Length normalization\n",
    "\n",
    "$$\\frac{x}{||x||}$$\n",
    "\n",
    "**Length of a vector**\n",
    "$$||x|| = \\sqrt{x \\cdot x} = \\sqrt{\\sum_{i=1}^nx_i^2}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2644666-ae29-42af-91a9-44de31e7d177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def length_normalization(vector: list[float]) -> list[float] :\n",
    "    \"\"\"\n",
    "    A method for normalizing a vector.\n",
    "    \n",
    "    Args: \n",
    "        vector1 (list[float]): a list representing a vector.\n",
    "         \n",
    "        \n",
    "    Returns: \n",
    "        normalized_vector (list[float]): the sum of the calculation.\n",
    "        \n",
    "    Raises: \n",
    "        ValueError: If it is a zero-length vector. \n",
    "    \"\"\"\n",
    "    \n",
    " \n",
    "    \n",
    "    total = 0\n",
    "    for element in vector: \n",
    "        total += element ** 2\n",
    "    length = math.sqrt(total)\n",
    "    \n",
    "    if length == 0: \n",
    "        raise ValueError(\"cannot normalize a zero-length vector\")\n",
    "    normalized_vector = [x/ length for x in vector]\n",
    "\n",
    "    return normalized_vector\n",
    "\n",
    "#TODO add doc strings and examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796ba0b0-760e-4b27-bc27-2c45553b8906",
   "metadata": {},
   "source": [
    "# Cosine similarity\n",
    "\n",
    "TODO - everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "356fca95-a65c-4b0a-8a68-65cc5699f8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vector1: list[float], vector2 : list[float]) -> float :\n",
    "    \"\"\"\n",
    "    A method for finding the cosine similarity of two vectors.\n",
    "    \n",
    "    Args: \n",
    "        vector1 (list[float]): a list representing a vector.\n",
    "        vector2 (list[float]): a list representing a different vector. \n",
    "        \n",
    "    Returns: \n",
    "        dotproduct (float): the dot product of the normalized vectors.\n",
    "        \n",
    "    Raises: \n",
    "        ValueError: If the vectors are not of the same length. \n",
    "    \"\"\"\n",
    "    \n",
    "    if len(vector1) != len(vector2):\n",
    "        raise ValueError(\"Vectors must be of the same length\")\n",
    "    if all(v == 0 for v in vector1) or all(v == 0 for v in vector2): \n",
    "        return 0.0\n",
    "        \n",
    "    \n",
    "    vector1_normalized = length_normalization(vector1)\n",
    "    vector2_normalized = length_normalization(vector2)\n",
    "    \n",
    "    return dot_product(vector1_normalized, vector2_normalized)\n",
    "\n",
    "#TODO add examples\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de65f082-2122-4714-a201-dc6aa028d1b0",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398ab710-4948-4e43-8531-a20877865d86",
   "metadata": {},
   "source": [
    "# Mini project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cac4d8-c1b0-46ee-badc-7d9e22661bc8",
   "metadata": {},
   "source": [
    "# Mini project - using external libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a175fc47-a247-4029-90ff-3afcf33fc9f0",
   "metadata": {},
   "source": [
    "# About, credits and so on. \n",
    "\n",
    "## How have I used LLMs\n",
    "\n",
    "## Where can you read more about these concepts? \n",
    "\n",
    "## How do I draw on In2110 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
